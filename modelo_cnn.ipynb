{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40799b4a-6fa0-4f43-8dfc-6e6d883cc5c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 17:14:35.376772: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-23 17:14:35.789430: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-10-23 17:14:38.195055: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "#importação das bibliotecas necessárias \n",
    "#variaveis globais \n",
    "#configuração da gpu\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os \n",
    "\n",
    "img_size = (224,224)\n",
    "seed = 42\n",
    "batch_size = 32\n",
    "epochs = 80 \n",
    "\n",
    "print(tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa5fb120-2962-4d01-bf8c-be67bb9afa2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3796 files belonging to 4 classes.\n",
      "Using 3037 files for training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761250481.863804    6294 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4151 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 6GB Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3796 files belonging to 4 classes.\n",
      "Using 759 files for validation.\n",
      "Found 429 files belonging to 4 classes.\n",
      "Classes encontradas: ['cataract', 'diabetic_retinopathy', 'glaucoma', 'normal']\n",
      "Número de classes: 4\n"
     ]
    }
   ],
   "source": [
    "#Carregamento base de dados \n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"data/dataset_eye_disease/train/\",\n",
    "    validation_split=0.2,      \n",
    "    subset=\"training\",\n",
    "    seed=seed,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"data/dataset_eye_disease/train/\",\n",
    "    validation_split=0.2,\n",
    "    subset=\"validation\",\n",
    "    seed=seed,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"data/dataset_eye_disease/test/\",\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "num_classes = len(class_names)\n",
    "\n",
    "print(f\"Classes encontradas: {class_names}\")\n",
    "print(f\"Número de classes: {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "952771a1-4512-4f02-95ff-ca0afa2f9396",
   "metadata": {},
   "outputs": [],
   "source": [
    "#otimiza carregamento de dados\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "#pipeline do data augmentation e as transformações\n",
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "        tf.keras.layers.RandomRotation(0.07),\n",
    "        tf.keras.layers.RandomZoom(0.1),\n",
    "        tf.keras.layers.RandomTranslation(0.07, 0.07),\n",
    "        tf.keras.layers.RandomBrightness(0.15),\n",
    "        tf.keras.layers.RandomContrast(0.1)\n",
    "    ],\n",
    "    name=\"data_augmentation_clinical\"\n",
    ")\n",
    "\n",
    "#pré processamento dos dados de treino\n",
    "train_ds = (\n",
    "    train_ds\n",
    "    .map(lambda x, y: (data_augmentation(x, training=True), y),\n",
    "         num_parallel_calls=AUTOTUNE)\n",
    "    .shuffle(1000, seed=seed)\n",
    "    .cache()\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "#pré processamento dos dados de validação \n",
    "val_ds = (\n",
    "    val_ds\n",
    "    .cache()\n",
    "    .prefetch(AUTOTUNE)\n",
    ")\n",
    "\n",
    "#pré processamento dos dados de teste\n",
    "test_ds = (\n",
    "    test_ds\n",
    "    .cache()\n",
    "    .prefetch(AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d6b6f3a-978e-4102-a627-9b67543388b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lucas/anaconda3/envs/tf_gpu_pip/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Rescaling</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,792</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">112</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_1             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_2             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">590,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">28</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_3             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">SpatialDropout2D</span>)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">516</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ rescaling (\u001b[38;5;33mRescaling\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │         \u001b[38;5;34m1,792\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m112\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_1             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m128\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m56\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_2             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_7 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │       \u001b[38;5;34m590,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_7           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m28\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ spatial_dropout2d_3             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m256\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mSpatialDropout2D\u001b[0m)              │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ global_average_pooling2d        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)        │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m131,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_8           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_9           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m516\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,531,524</span> (9.66 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,531,524\u001b[0m (9.66 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,527,428</span> (9.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,527,428\u001b[0m (9.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,096</span> (16.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,096\u001b[0m (16.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#toda a arquitetura do modelo\n",
    "\n",
    "from tensorflow.keras import layers, regularizers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "        layers.Input(shape=(224, 224, 3)),\n",
    "        layers.Rescaling(1./255),\n",
    "\n",
    "        #primeiro bloco convolucional\n",
    "        layers.Conv2D(64, (3, 3), padding='same', activation='relu', input_shape=(224,224,3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(64, (3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.SpatialDropout2D(0.15),\n",
    "\n",
    "        #segundo bloco convolucional\n",
    "        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(128, (3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.SpatialDropout2D(0.20),\n",
    "\n",
    "        #terceiro bloco convolucional\n",
    "        layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.SpatialDropout2D(0.25),\n",
    "\n",
    "        #quarto bloco convolucional\n",
    "        layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Conv2D(256, (3, 3), padding='same', activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.SpatialDropout2D(0.30),\n",
    "\n",
    "        #camada densa\n",
    "        layers.GlobalAveragePooling2D(),\n",
    "        layers.Dense(512, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(4, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6adbda96-9184-48c6-b117-98f91b9084b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definição do otimizador e compilação do modelo\n",
    "from tensorflow.keras.optimizers.schedules import CosineDecayRestarts\n",
    "\n",
    "#define um agendador de taxa de aprendizado cíclico\n",
    "lr_schedule = CosineDecayRestarts(\n",
    "    initial_learning_rate=3e-4, #taxa de aprendizado inicial\n",
    "    first_decay_steps=15,  #duração do primeiro ciclo em épocas\n",
    "    t_mul=1.5,   #multiplica o tamanho de cada ciclo subsequente\n",
    "    m_mul=0.9,   #reduz a amplitude máxima do LR a cada reinício\n",
    "    alpha=1e-6   #taxa mínima \n",
    ")\n",
    "#define o otimizador AdamW\n",
    "optimizer = tf.keras.optimizers.AdamW(learning_rate=lr_schedule, weight_decay=1e-5)\n",
    "\n",
    "#Compilação do modelo com as métricas e loss\n",
    "model.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ea1d4dd-3f8b-48f2-ae84-bb20aacd8b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#definição dos callbacks\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "\n",
    "#early stoppin para parar o treinamento se o modelo não aprender\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',       #métrica a ser avaliada     \n",
    "    patience=40,              #quantas épocas até parar o treinamento \n",
    "    restore_best_weights=True, #restaura os melhores pesos\n",
    "    verbose = 1 #manda msg que parou\n",
    ")\n",
    "\n",
    "#callback para salvar o melhor modelo\n",
    "checkpoint = ModelCheckpoint(\n",
    "    filepath='best_model.keras', #o nome do arquivo que vai salvar\n",
    "    monitor='val_loss', #métrica que vai ser avaliada\n",
    "    save_best_only=True,  #salvar apenas o melhor\n",
    "    verbose=1 #manda msg que salvou\n",
    ")\n",
    "\n",
    "\n",
    "callbacks_list = [early_stopping,  checkpoint]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9dfe6d42-31fe-4db9-a116-d471d6dab457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 17:24:12.870443: I external/local_xla/xla/service/service.cc:163] XLA service 0x7ec128036ae0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-22 17:24:12.870459: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 6GB Laptop GPU, Compute Capability 8.6\n",
      "2025-10-22 17:24:13.041296: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-22 17:24:14.014453: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n",
      "2025-10-22 17:24:14.428970: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-10-22 17:24:14.428993: I external/local_xla/xla/service/gpu/autotuning/dot_search_space.cc:208] All configs were filtered out because none of them sufficiently match the hints. Maybe the hints set does not contain a good representative set of valid configs? Working around this by using the full hints set instead.\n",
      "2025-10-22 17:24:15.372620: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8161', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n",
      "2025-10-22 17:24:15.927985: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8178', 520 bytes spill stores, 520 bytes spill loads\n",
      "\n",
      "2025-10-22 17:24:16.220764: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_8161', 520 bytes spill stores, 520 bytes spill loads\n",
      "\n",
      "2025-10-22 17:24:19.132253: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-10-22 17:24:37.446201: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv (f32[32,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,224,224]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2025-10-22 17:24:37.885292: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.439234493s\n",
      "Trying algorithm eng0{} for conv (f32[32,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,64,224,224]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2025-10-22 17:24:42.642503: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.41GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1761164698.199224    6150 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/95\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 488ms/step - accuracy: 0.2890 - loss: 2.0259"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 17:25:27.767884: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 2.94GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2025-10-22 17:25:45.024696: E external/local_xla/xla/service/slow_operation_alarm.cc:73] Trying algorithm eng0{} for conv (f32[29,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,64,224,224]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n",
      "2025-10-22 17:25:45.336187: E external/local_xla/xla/service/slow_operation_alarm.cc:140] The operation took 1.311540997s\n",
      "Trying algorithm eng0{} for conv (f32[29,64,224,224]{3,2,1,0}, u8[0]{0}) custom-call(f32[29,64,224,224]{3,2,1,0}, f32[64,64,3,3]{3,2,1,0}), window={size=3x3 pad=1_1x1_1}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"activation_mode\":\"kNone\",\"conv_result_scale\":1,\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false,\"reification_cost\":[]} is taking a while...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 932ms/step - accuracy: 0.3087 - loss: 1.9608"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-22 17:26:29.117777: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from None to 1.40673, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m167s\u001b[0m 1s/step - accuracy: 0.3388 - loss: 1.8635 - val_accuracy: 0.2227 - val_loss: 1.4067\n",
      "Epoch 2/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.3901 - loss: 1.6473\n",
      "Epoch 2: val_loss did not improve from 1.40673\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.3793 - loss: 1.6672 - val_accuracy: 0.2767 - val_loss: 1.4319\n",
      "Epoch 3/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.4000 - loss: 1.5888\n",
      "Epoch 3: val_loss did not improve from 1.40673\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 521ms/step - accuracy: 0.4083 - loss: 1.5640 - val_accuracy: 0.2978 - val_loss: 1.5623\n",
      "Epoch 4/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.4258 - loss: 1.4936\n",
      "Epoch 4: val_loss did not improve from 1.40673\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.4231 - loss: 1.5020 - val_accuracy: 0.2938 - val_loss: 1.7572\n",
      "Epoch 5/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.4486 - loss: 1.4038\n",
      "Epoch 5: val_loss improved from 1.40673 to 1.25797, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 523ms/step - accuracy: 0.4547 - loss: 1.3956 - val_accuracy: 0.4177 - val_loss: 1.2580\n",
      "Epoch 6/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.4601 - loss: 1.3634\n",
      "Epoch 6: val_loss improved from 1.25797 to 1.09252, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 524ms/step - accuracy: 0.4537 - loss: 1.4188 - val_accuracy: 0.4993 - val_loss: 1.0925\n",
      "Epoch 7/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.4929 - loss: 1.3295\n",
      "Epoch 7: val_loss improved from 1.09252 to 0.96131, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 523ms/step - accuracy: 0.4768 - loss: 1.3261 - val_accuracy: 0.5982 - val_loss: 0.9613\n",
      "Epoch 8/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.5165 - loss: 1.2061\n",
      "Epoch 8: val_loss did not improve from 0.96131\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.5058 - loss: 1.2461 - val_accuracy: 0.6403 - val_loss: 0.9834\n",
      "Epoch 9/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.5264 - loss: 1.2295\n",
      "Epoch 9: val_loss improved from 0.96131 to 0.88538, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 524ms/step - accuracy: 0.5143 - loss: 1.2510 - val_accuracy: 0.6430 - val_loss: 0.8854\n",
      "Epoch 10/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.5366 - loss: 1.1809\n",
      "Epoch 10: val_loss improved from 0.88538 to 0.85729, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 523ms/step - accuracy: 0.5380 - loss: 1.1778 - val_accuracy: 0.6601 - val_loss: 0.8573\n",
      "Epoch 11/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.5782 - loss: 1.0794\n",
      "Epoch 11: val_loss improved from 0.85729 to 0.75558, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 523ms/step - accuracy: 0.5687 - loss: 1.1152 - val_accuracy: 0.6996 - val_loss: 0.7556\n",
      "Epoch 12/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.5665 - loss: 1.0624\n",
      "Epoch 12: val_loss did not improve from 0.75558\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.5706 - loss: 1.0806 - val_accuracy: 0.6680 - val_loss: 0.8081\n",
      "Epoch 13/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.5659 - loss: 1.1144\n",
      "Epoch 13: val_loss did not improve from 0.75558\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.5509 - loss: 1.1413 - val_accuracy: 0.6588 - val_loss: 0.8322\n",
      "Epoch 14/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.5512 - loss: 1.1025\n",
      "Epoch 14: val_loss did not improve from 0.75558\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.5525 - loss: 1.1034 - val_accuracy: 0.6996 - val_loss: 0.7741\n",
      "Epoch 15/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.5866 - loss: 1.0135\n",
      "Epoch 15: val_loss did not improve from 0.75558\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.5907 - loss: 1.0264 - val_accuracy: 0.6825 - val_loss: 0.8226\n",
      "Epoch 16/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.6005 - loss: 0.9911\n",
      "Epoch 16: val_loss improved from 0.75558 to 0.72561, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 523ms/step - accuracy: 0.6016 - loss: 0.9970 - val_accuracy: 0.7181 - val_loss: 0.7256\n",
      "Epoch 17/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.6217 - loss: 0.9139\n",
      "Epoch 17: val_loss did not improve from 0.72561\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6220 - loss: 0.9311 - val_accuracy: 0.7075 - val_loss: 0.7598\n",
      "Epoch 18/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.6171 - loss: 0.9482\n",
      "Epoch 18: val_loss did not improve from 0.72561\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6197 - loss: 0.9605 - val_accuracy: 0.7075 - val_loss: 0.7500\n",
      "Epoch 19/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.6165 - loss: 0.9494\n",
      "Epoch 19: val_loss did not improve from 0.72561\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6131 - loss: 0.9812 - val_accuracy: 0.7022 - val_loss: 0.7619\n",
      "Epoch 20/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.6055 - loss: 0.9751\n",
      "Epoch 20: val_loss did not improve from 0.72561\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6088 - loss: 0.9812 - val_accuracy: 0.7115 - val_loss: 0.7395\n",
      "Epoch 21/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.6373 - loss: 0.9093\n",
      "Epoch 21: val_loss improved from 0.72561 to 0.69390, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 523ms/step - accuracy: 0.6273 - loss: 0.9365 - val_accuracy: 0.7088 - val_loss: 0.6939\n",
      "Epoch 22/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.6426 - loss: 0.8826\n",
      "Epoch 22: val_loss did not improve from 0.69390\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6322 - loss: 0.9168 - val_accuracy: 0.6970 - val_loss: 0.7647\n",
      "Epoch 23/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.6484 - loss: 0.8647\n",
      "Epoch 23: val_loss did not improve from 0.69390\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6411 - loss: 0.8894 - val_accuracy: 0.7273 - val_loss: 0.6950\n",
      "Epoch 24/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.6627 - loss: 0.8373\n",
      "Epoch 24: val_loss improved from 0.69390 to 0.68105, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 524ms/step - accuracy: 0.6497 - loss: 0.8719 - val_accuracy: 0.7404 - val_loss: 0.6811\n",
      "Epoch 25/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.6655 - loss: 0.8183\n",
      "Epoch 25: val_loss did not improve from 0.68105\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6460 - loss: 0.8525 - val_accuracy: 0.7273 - val_loss: 0.7246\n",
      "Epoch 26/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.6501 - loss: 0.8080\n",
      "Epoch 26: val_loss did not improve from 0.68105\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6572 - loss: 0.8345 - val_accuracy: 0.7312 - val_loss: 0.7005\n",
      "Epoch 27/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.6589 - loss: 0.8334\n",
      "Epoch 27: val_loss did not improve from 0.68105\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6510 - loss: 0.8508 - val_accuracy: 0.7312 - val_loss: 0.7002\n",
      "Epoch 28/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.6367 - loss: 0.8882\n",
      "Epoch 28: val_loss did not improve from 0.68105\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6362 - loss: 0.8948 - val_accuracy: 0.7246 - val_loss: 0.7038\n",
      "Epoch 29/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.6421 - loss: 0.8310\n",
      "Epoch 29: val_loss did not improve from 0.68105\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6414 - loss: 0.8647 - val_accuracy: 0.7115 - val_loss: 0.7039\n",
      "Epoch 30/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.6617 - loss: 0.8200\n",
      "Epoch 30: val_loss did not improve from 0.68105\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6546 - loss: 0.8661 - val_accuracy: 0.7075 - val_loss: 0.7229\n",
      "Epoch 31/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.6665 - loss: 0.8169\n",
      "Epoch 31: val_loss did not improve from 0.68105\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6648 - loss: 0.8342 - val_accuracy: 0.7312 - val_loss: 0.6842\n",
      "Epoch 32/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 489ms/step - accuracy: 0.6804 - loss: 0.7707\n",
      "Epoch 32: val_loss improved from 0.68105 to 0.66492, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 523ms/step - accuracy: 0.6681 - loss: 0.8221 - val_accuracy: 0.7378 - val_loss: 0.6649\n",
      "Epoch 33/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.6716 - loss: 0.8036\n",
      "Epoch 33: val_loss did not improve from 0.66492\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6691 - loss: 0.8164 - val_accuracy: 0.7299 - val_loss: 0.6736\n",
      "Epoch 34/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.6909 - loss: 0.7415\n",
      "Epoch 34: val_loss did not improve from 0.66492\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6796 - loss: 0.7799 - val_accuracy: 0.7378 - val_loss: 0.6802\n",
      "Epoch 35/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.6926 - loss: 0.7405\n",
      "Epoch 35: val_loss did not improve from 0.66492\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6852 - loss: 0.7725 - val_accuracy: 0.7365 - val_loss: 0.6907\n",
      "Epoch 36/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.6961 - loss: 0.7481\n",
      "Epoch 36: val_loss improved from 0.66492 to 0.65129, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 523ms/step - accuracy: 0.6852 - loss: 0.7667 - val_accuracy: 0.7444 - val_loss: 0.6513\n",
      "Epoch 37/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.6972 - loss: 0.7559\n",
      "Epoch 37: val_loss did not improve from 0.65129\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.6938 - loss: 0.7681 - val_accuracy: 0.7444 - val_loss: 0.6538\n",
      "Epoch 38/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.7073 - loss: 0.7080\n",
      "Epoch 38: val_loss improved from 0.65129 to 0.64767, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 524ms/step - accuracy: 0.6987 - loss: 0.7331 - val_accuracy: 0.7523 - val_loss: 0.6477\n",
      "Epoch 39/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.7090 - loss: 0.7038\n",
      "Epoch 39: val_loss did not improve from 0.64767\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 527ms/step - accuracy: 0.6951 - loss: 0.7374 - val_accuracy: 0.7549 - val_loss: 0.6485\n",
      "Epoch 40/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7172 - loss: 0.7074\n",
      "Epoch 40: val_loss did not improve from 0.64767\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 526ms/step - accuracy: 0.7053 - loss: 0.7289 - val_accuracy: 0.7523 - val_loss: 0.6519\n",
      "Epoch 41/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7006 - loss: 0.7115\n",
      "Epoch 41: val_loss did not improve from 0.64767\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 525ms/step - accuracy: 0.6895 - loss: 0.7652 - val_accuracy: 0.7497 - val_loss: 0.6503\n",
      "Epoch 42/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - accuracy: 0.6908 - loss: 0.7444\n",
      "Epoch 42: val_loss did not improve from 0.64767\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 525ms/step - accuracy: 0.6780 - loss: 0.7831 - val_accuracy: 0.7352 - val_loss: 0.6865\n",
      "Epoch 43/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.6770 - loss: 0.7871\n",
      "Epoch 43: val_loss improved from 0.64767 to 0.63869, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 527ms/step - accuracy: 0.6796 - loss: 0.7873 - val_accuracy: 0.7470 - val_loss: 0.6387\n",
      "Epoch 44/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.6958 - loss: 0.7336\n",
      "Epoch 44: val_loss did not improve from 0.63869\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 526ms/step - accuracy: 0.6948 - loss: 0.7469 - val_accuracy: 0.7444 - val_loss: 0.6536\n",
      "Epoch 45/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.6986 - loss: 0.7308\n",
      "Epoch 45: val_loss did not improve from 0.63869\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 526ms/step - accuracy: 0.6928 - loss: 0.7604 - val_accuracy: 0.7470 - val_loss: 0.6576\n",
      "Epoch 46/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7160 - loss: 0.7158\n",
      "Epoch 46: val_loss improved from 0.63869 to 0.63089, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 527ms/step - accuracy: 0.7073 - loss: 0.7505 - val_accuracy: 0.7563 - val_loss: 0.6309\n",
      "Epoch 47/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - accuracy: 0.7085 - loss: 0.6928\n",
      "Epoch 47: val_loss did not improve from 0.63089\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 524ms/step - accuracy: 0.7040 - loss: 0.7264 - val_accuracy: 0.7246 - val_loss: 0.6890\n",
      "Epoch 48/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - accuracy: 0.7124 - loss: 0.7000\n",
      "Epoch 48: val_loss did not improve from 0.63089\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 524ms/step - accuracy: 0.7020 - loss: 0.7389 - val_accuracy: 0.7444 - val_loss: 0.6331\n",
      "Epoch 49/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7058 - loss: 0.7039\n",
      "Epoch 49: val_loss improved from 0.63089 to 0.60715, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 528ms/step - accuracy: 0.7017 - loss: 0.7244 - val_accuracy: 0.7470 - val_loss: 0.6072\n",
      "Epoch 50/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7147 - loss: 0.6782\n",
      "Epoch 50: val_loss improved from 0.60715 to 0.60225, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 527ms/step - accuracy: 0.7056 - loss: 0.7037 - val_accuracy: 0.7523 - val_loss: 0.6023\n",
      "Epoch 51/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7162 - loss: 0.6781\n",
      "Epoch 51: val_loss did not improve from 0.60225\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 526ms/step - accuracy: 0.7149 - loss: 0.6974 - val_accuracy: 0.7325 - val_loss: 0.6529\n",
      "Epoch 52/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.7281 - loss: 0.6701\n",
      "Epoch 52: val_loss did not improve from 0.60225\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 526ms/step - accuracy: 0.7228 - loss: 0.6892 - val_accuracy: 0.7273 - val_loss: 0.6485\n",
      "Epoch 53/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7369 - loss: 0.6597\n",
      "Epoch 53: val_loss did not improve from 0.60225\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 526ms/step - accuracy: 0.7303 - loss: 0.6713 - val_accuracy: 0.7418 - val_loss: 0.6271\n",
      "Epoch 54/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.7428 - loss: 0.6390\n",
      "Epoch 54: val_loss did not improve from 0.60225\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 527ms/step - accuracy: 0.7353 - loss: 0.6706 - val_accuracy: 0.7457 - val_loss: 0.6362\n",
      "Epoch 55/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.7331 - loss: 0.6433\n",
      "Epoch 55: val_loss did not improve from 0.60225\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 527ms/step - accuracy: 0.7237 - loss: 0.6703 - val_accuracy: 0.7497 - val_loss: 0.6351\n",
      "Epoch 56/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - accuracy: 0.7391 - loss: 0.6304\n",
      "Epoch 56: val_loss did not improve from 0.60225\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 525ms/step - accuracy: 0.7399 - loss: 0.6469 - val_accuracy: 0.7602 - val_loss: 0.6037\n",
      "Epoch 57/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7461 - loss: 0.6163\n",
      "Epoch 57: val_loss did not improve from 0.60225\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 526ms/step - accuracy: 0.7402 - loss: 0.6420 - val_accuracy: 0.7549 - val_loss: 0.6195\n",
      "Epoch 58/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - accuracy: 0.7443 - loss: 0.6348\n",
      "Epoch 58: val_loss did not improve from 0.60225\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 525ms/step - accuracy: 0.7409 - loss: 0.6482 - val_accuracy: 0.7576 - val_loss: 0.6188\n",
      "Epoch 59/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7494 - loss: 0.6124\n",
      "Epoch 59: val_loss did not improve from 0.60225\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 526ms/step - accuracy: 0.7465 - loss: 0.6281 - val_accuracy: 0.7615 - val_loss: 0.6108\n",
      "Epoch 60/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7525 - loss: 0.6065\n",
      "Epoch 60: val_loss did not improve from 0.60225\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 526ms/step - accuracy: 0.7392 - loss: 0.6366 - val_accuracy: 0.7642 - val_loss: 0.6112\n",
      "Epoch 61/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7317 - loss: 0.6380\n",
      "Epoch 61: val_loss did not improve from 0.60225\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 526ms/step - accuracy: 0.7293 - loss: 0.6567 - val_accuracy: 0.7602 - val_loss: 0.6120\n",
      "Epoch 62/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7322 - loss: 0.6453\n",
      "Epoch 62: val_loss did not improve from 0.60225\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 526ms/step - accuracy: 0.7228 - loss: 0.6820 - val_accuracy: 0.6772 - val_loss: 0.6987\n",
      "Epoch 63/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7220 - loss: 0.6669\n",
      "Epoch 63: val_loss did not improve from 0.60225\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 526ms/step - accuracy: 0.7185 - loss: 0.6896 - val_accuracy: 0.7431 - val_loss: 0.6382\n",
      "Epoch 64/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 492ms/step - accuracy: 0.7207 - loss: 0.6605\n",
      "Epoch 64: val_loss improved from 0.60225 to 0.59647, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 527ms/step - accuracy: 0.7139 - loss: 0.6772 - val_accuracy: 0.7694 - val_loss: 0.5965\n",
      "Epoch 65/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.7323 - loss: 0.6457\n",
      "Epoch 65: val_loss did not improve from 0.59647\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 527ms/step - accuracy: 0.7287 - loss: 0.6788 - val_accuracy: 0.7642 - val_loss: 0.6165\n",
      "Epoch 66/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - accuracy: 0.7310 - loss: 0.6532\n",
      "Epoch 66: val_loss did not improve from 0.59647\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 529ms/step - accuracy: 0.7264 - loss: 0.6743 - val_accuracy: 0.7391 - val_loss: 0.6556\n",
      "Epoch 67/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.7459 - loss: 0.6393\n",
      "Epoch 67: val_loss did not improve from 0.59647\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 527ms/step - accuracy: 0.7415 - loss: 0.6502 - val_accuracy: 0.7602 - val_loss: 0.6212\n",
      "Epoch 68/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.7339 - loss: 0.6381\n",
      "Epoch 68: val_loss did not improve from 0.59647\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 526ms/step - accuracy: 0.7323 - loss: 0.6578 - val_accuracy: 0.7628 - val_loss: 0.6049\n",
      "Epoch 69/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 496ms/step - accuracy: 0.7417 - loss: 0.6349\n",
      "Epoch 69: val_loss did not improve from 0.59647\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 529ms/step - accuracy: 0.7448 - loss: 0.6373 - val_accuracy: 0.7642 - val_loss: 0.6051\n",
      "Epoch 70/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.7492 - loss: 0.6129\n",
      "Epoch 70: val_loss improved from 0.59647 to 0.57938, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 529ms/step - accuracy: 0.7419 - loss: 0.6370 - val_accuracy: 0.7747 - val_loss: 0.5794\n",
      "Epoch 71/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.7581 - loss: 0.6194\n",
      "Epoch 71: val_loss did not improve from 0.57938\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 527ms/step - accuracy: 0.7488 - loss: 0.6354 - val_accuracy: 0.7220 - val_loss: 0.6158\n",
      "Epoch 72/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 494ms/step - accuracy: 0.7539 - loss: 0.6034\n",
      "Epoch 72: val_loss did not improve from 0.57938\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 527ms/step - accuracy: 0.7514 - loss: 0.6211 - val_accuracy: 0.7839 - val_loss: 0.5801\n",
      "Epoch 73/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7467 - loss: 0.6018\n",
      "Epoch 73: val_loss did not improve from 0.57938\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 526ms/step - accuracy: 0.7537 - loss: 0.6047 - val_accuracy: 0.7128 - val_loss: 0.6635\n",
      "Epoch 74/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 495ms/step - accuracy: 0.7508 - loss: 0.6008\n",
      "Epoch 74: val_loss did not improve from 0.57938\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 527ms/step - accuracy: 0.7563 - loss: 0.6086 - val_accuracy: 0.7642 - val_loss: 0.6025\n",
      "Epoch 75/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7627 - loss: 0.5874\n",
      "Epoch 75: val_loss did not improve from 0.57938\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 525ms/step - accuracy: 0.7705 - loss: 0.5905 - val_accuracy: 0.7655 - val_loss: 0.5994\n",
      "Epoch 76/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7767 - loss: 0.5666\n",
      "Epoch 76: val_loss did not improve from 0.57938\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 526ms/step - accuracy: 0.7692 - loss: 0.5812 - val_accuracy: 0.7286 - val_loss: 0.6287\n",
      "Epoch 77/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 493ms/step - accuracy: 0.7669 - loss: 0.5686\n",
      "Epoch 77: val_loss improved from 0.57938 to 0.57461, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 527ms/step - accuracy: 0.7738 - loss: 0.5627 - val_accuracy: 0.7892 - val_loss: 0.5746\n",
      "Epoch 78/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.7889 - loss: 0.5406\n",
      "Epoch 78: val_loss did not improve from 0.57461\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.7879 - loss: 0.5409 - val_accuracy: 0.7365 - val_loss: 0.6032\n",
      "Epoch 79/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.7798 - loss: 0.5493\n",
      "Epoch 79: val_loss improved from 0.57461 to 0.55192, saving model to best_model.keras\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 524ms/step - accuracy: 0.7718 - loss: 0.5549 - val_accuracy: 0.8024 - val_loss: 0.5519\n",
      "Epoch 80/80\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.7923 - loss: 0.5169\n",
      "Epoch 80: val_loss did not improve from 0.55192\n",
      "\u001b[1m95/95\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 522ms/step - accuracy: 0.7860 - loss: 0.5274 - val_accuracy: 0.7879 - val_loss: 0.5616\n",
      "Restoring model weights from the end of the best epoch: 79.\n"
     ]
    }
   ],
   "source": [
    "#treinamento do modelo\n",
    "history = model.fit(\n",
    "    train_ds,\n",
    "    epochs=epochs,\n",
    "    validation_data=val_ds,\n",
    "    callbacks=callbacks_list\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74503902-5e51-42c0-85bd-02c930c775f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/24\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 129ms/step - accuracy: 0.8024 - loss: 0.5519\n",
      "Acurácia de Validação: 0.8024\n",
      "Perda de Validação: 0.5519\n"
     ]
    }
   ],
   "source": [
    "#mostra das métricas no conjunto de dados de validação\n",
    "val_loss, val_acc = model.evaluate(val_ds)\n",
    "print(f\"Acurácia de Validação: {val_acc:.4f}\")\n",
    "print(f\"Perda de Validação: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "60050320-8d9e-4873-8bd6-f5dcf5cec3d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 17:16:57.941671: I external/local_xla/xla/service/service.cc:163] XLA service 0x778558011a10 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-10-23 17:16:57.941698: I external/local_xla/xla/service/service.cc:171]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 6GB Laptop GPU, Compute Capability 8.6\n",
      "2025-10-23 17:16:57.980948: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-10-23 17:16:58.178823: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91002\n",
      "2025-10-23 17:17:01.710309: W external/local_xla/xla/tsl/framework/bfc_allocator.cc:310] Allocator (GPU_0_bfc) ran out of memory trying to allocate 3.04GiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "I0000 00:00:1761250630.107130    6641 device_compiler.h:196] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-10-23 17:17:25.735662: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "#Importação e carregamento do modelo treinado \n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "#carregamento do melhor modelo \n",
    "model_path = Path(\"best_model.keras\")\n",
    "model = load_model(model_path)\n",
    "\n",
    "#listas de valores verdadeiros e preditos\n",
    "y_true = []\n",
    "y_pred = []\n",
    "\n",
    "#geração das previsões sobre o conjunto de validação\n",
    "for images, labels in val_ds:\n",
    "    preds = model.predict(images, verbose=0)\n",
    "    y_pred.extend(np.argmax(preds, axis=1))\n",
    "    y_true.extend(labels.numpy())\n",
    "\n",
    "#conversão para numpy arrays\n",
    "y_true = np.array(y_true)\n",
    "y_pred = np.array(y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "986c7db2-9281-479b-bf68-efae1c0144d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print matriz \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)\n",
    "plt.xlabel(\"Predito\")\n",
    "plt.ylabel(\"Verdadeiro\")\n",
    "plt.title(\"Matriz de Confusão - Conjunto de Validação\")\n",
    "plt.savefig(\"confusion_matrix.png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83949623-290c-4da8-afad-ef04e2bf4182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatório de Classificação:\n",
      "\n",
      "                      precision    recall  f1-score   support\n",
      "\n",
      "            cataract     0.9139    0.8166    0.8625       169\n",
      "diabetic_retinopathy     0.8702    0.8619    0.8660       210\n",
      "            glaucoma     0.7160    0.7250    0.7205       160\n",
      "              normal     0.7311    0.7909    0.7598       220\n",
      "\n",
      "            accuracy                         0.8024       759\n",
      "           macro avg     0.8078    0.7986    0.8022       759\n",
      "        weighted avg     0.8071    0.8024    0.8038       759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#print das métricas por classe\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "report = classification_report(y_true, y_pred, target_names=class_names, digits=4)\n",
    "print(\"Relatório de Classificação:\\n\")\n",
    "print(report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow GPU via Pip)",
   "language": "python",
   "name": "tf_gpu_pip"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
